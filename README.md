# SynthID-Bypass: An Exploration of Digital Watermark Robustness in Generative AI

**Disclaimer:** *This project is intended for educational and AI safety research purposes only. The goal is to scrutinize the robustness of current AI-generated content detection mechanisms and to foster a proactive dialogue on developing more resilient watermarking technologies. The tools and techniques described herein should not be used for malicious purposes, to circumvent copyright, or to misrepresent the origin of digital content. The author assumes no liability for any misuse of this information.*

---

## 1. Overview

This repository contains a proof-of-concept exploration into the robustness of Google's SynthID, a digital watermarking technology designed to identify AI-generated images. Through the use of custom-built ComfyUI workflows, this research demonstrates a technique that can successfully remove or invalidate the SynthID watermark from images generated by Google's AI models, including Gemini. 

The primary objective of this research is not to enable malicious actors, but to highlight a potential vulnerability in current watermarking schemes. By demonstrating this bypass, we aim to encourage the AI safety and research community to develop more robust and resilient methods for identifying synthetic media. This work serves as a call to action for red-teaming and collaborative improvement of AI safety measures.

### Key Findings

- It is possible to disrupt the SynthID watermark by re-processing an image through a carefully configured diffusion model pipeline.
- The core technique involves using the original image as a structural and compositional guide for a diffusion model, which effectively "re-renders" the image with a low-denoising factor. This process preserves the visual content while discarding the subtle, embedded watermark.
- We present two workflows: a general-purpose workflow for any image and a specialized workflow optimized for portraits, which employs more sophisticated face detection and inpainting techniques.

## 2. The Bypass in Action: Before & After

The effectiveness of the bypass is evident when comparing the original, watermarked images with the processed, non-watermarked outputs. Furthermore, screenshots from a SynthID detection tool (such as Gemini's built-in analyzer) confirm the removal of the watermark.

### Example 1: General Image

| Original (Watermarked) | Processed (Watermark Removed) |
| :---: | :---: |
| ![Original Image 1](examples_before/01.png) | ![Processed Image 1](examples_after/01.png) |

| **SynthID Check: BEFORE** | **SynthID Check: AFTER** |
| :---: | :---: |
| ![SynthID Fail](synthid_check/before/01_fail.png) | ![SynthID Pass](synthid_check/after/01_pass.png) |

As demonstrated, the detection tool confidently identifies the original image as AI-generated, but after processing, it concludes that the image does not contain a SynthID watermark.

### Example 2: Portrait Image

| Original (Watermarked) | Processed (Watermark Removed) |
| :---: | :---: |
| ![Original Image 2](examples_before/02.png) | ![Processed Image 2](examples_after/02.png) |

| **SynthID Check: BEFORE** | **SynthID Check: AFTER** |
| :---: | :---: |
| ![SynthID Fail 2](synthid_check/before/02_fail.png) | ![SynthID Pass 2](synthid_check/after/02_pass.png) |

This example showcases the workflow's ability to handle complex scenes with human subjects, preserving detail while removing the watermark.

## 3. Technical Analysis: How the Workflows Operate

The bypass technique is implemented as a ComfyUI workflow. It leverages a combination of diffusion models, control models, and specialized nodes to reconstruct the source image in a way that discards the watermark. The process can be thought of as a "laundering" of pixels, where the semantic and structural information is kept, but the low-level, watermark-carrying noise is replaced.

### 3.1. General Purpose Workflow (`Synthid_Bypass.json`)

This workflow is designed to handle a wide variety of images. Its architecture is a multi-stage pipeline that carefully balances fidelity to the original image with the introduction of new pixel data.

![General Workflow Diagram](workflow_screenshots/Synthid_Bypass.png)

| Node/Stage | Purpose |
| :--- | :--- |
| **Load Image** | Inputs the source image containing the SynthID watermark. |
| **Model Loaders** | Loads the necessary models: `z_image_turbo` (diffusion), `qwen_3_4b` (CLIP), `ae.safetensors` (VAE), and ControlNet models. |
| **Canny Edge Detection** | Creates a structural outline (edge map) of the input image. This is a critical step for preserving the composition. |
| **QwenImageDiffsynthControlnet** | Applies the Canny edge map as a control signal to the diffusion model, ensuring the generated output adheres to the original structure. |
| **Sequential KSamplers** | The core of the process. The image is passed through three `KSampler` nodes in sequence, each with a very low `denoise` value (e.g., 0.2). This iteratively "repaints" the image, subtly altering pixel values enough to break the watermark. |
| **FaceDetailer** | An optional but powerful step that uses a YOLO model to detect faces and applies a separate, detailed sampling pass to enhance their quality, ensuring portraits do not degrade. |
| **Save Image** | Outputs the final, processed image. |

### 3.2. Portrait-Optimized Workflow (`Synthid_Bypass_Portrait.json`)

For images where facial fidelity is paramount, this workflow introduces additional steps to isolate and meticulously reconstruct facial features.

![Portrait Workflow Diagram](workflow_screenshots/Synthid_Bypass_Portrait.png)

Key enhancements in the portrait workflow include:

- **Face-Aware Masking:** It uses a `BboxDetectorCombined` to create a precise mask around faces.
- **Targeted Inpainting:** The `InpaintCropImproved` and `InpaintStitchImproved` nodes use this mask to isolate the facial region, process it with a dedicated set of samplers, and then seamlessly stitch it back into the main image. This allows for higher-resolution processing on the most important part of the image without affecting the background.
- **Dedicated Face Upscaling:** The `SeedVR2VideoUpscaler` is often applied specifically to the cropped facial region to enhance detail before it is stitched back.

## 4. Ethical Considerations & A Call for Community Collaboration

The existence of this bypass technique underscores a fundamental challenge in the field of synthetic media detection: the cat-and-mouse game between generation and detection. While watermarking is a crucial first step, it is not a panacea. As this research shows, watermarks embedded in the pixel space of a diffusion-generated image can be vulnerable to reconstruction-style attacks.

This project is released in the spirit of open and responsible AI safety research. We believe that the best way to build robust defenses is to understand the offenses. We encourage researchers, developers, and AI safety advocates to:

1.  **Test the Limits:** Use these workflows to test the boundaries of SynthID and other watermarking techniques. Can you create images that are resistant to this form of bypass?
2.  **Develop Better Techniques:** We challenge the community to develop and share more robust watermarking methods. Can watermarks be embedded in the semantic or frequency domains to be more resilient to pixel-level perturbations?
3.  **Contribute to the Dialogue:** Engage in the broader conversation about the responsible development and deployment of generative AI. How can we balance the creative potential of these tools with the need for authenticity and trust?

If you develop a technique that defeats these bypass workflows or have ideas for more robust watermarking, please open an issue or pull request in this repository to share your findings.

## 5. Setup & Usage

To run these workflows, you will need a functional ComfyUI installation with the necessary custom nodes and models.

### Dependencies

1.  **ComfyUI:** A recent version of [ComfyUI](https://github.com/comfyanonymous/ComfyUI).
2.  **ComfyUI Manager:** Recommended for installing custom nodes.
3.  **Custom Nodes:**
    - ComfyUI Impact Pack
    - ComfyUI-dype
    - rgthree-comfy
    - Masquerade Nodes
    - ComfyUI-Inpaint-CropAndStitch
    - SeedVR2 VideoUpscaler Nodes
4.  **Models:** You will need to download the required models and place them in the correct subdirectories within your ComfyUI `models` folder. The specific models are listed in the workflow JSON files and include, but are not limited to:
    - `ae.safetensors`
    - `z_image_turbo_bf16.safetensors`
    - `qwen_3_4b.safetensors`
    - `Z-Image-Turbo-Fun-Controlnet-Union.safetensors`
    - `yolov8n-face.pt`

### Instructions

1.  Install all required custom nodes and models.
2.  Drag and drop either `Synthid_Bypass.json` or `Synthid_Bypass_Portrait.json` onto your ComfyUI canvas.
3.  In the `Load Image` node, select the AI-generated image you wish to process.
4.  Click `Queue Prompt` to run the workflow.
5.  The final image will be saved in the default ComfyUI output directory.

### Model Download Links

The following table provides direct download links for the required models. Place them in the corresponding subdirectories within your ComfyUI `models` folder.

| Model File | Directory | Download Link |
| :--- | :--- | :--- |
| `ae.safetensors` | `vae/` | [Hugging Face](https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors) |
| `z_image_turbo_bf16.safetensors` | `diffusion_models/` | [Hugging Face](https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/diffusion_models/z_image_turbo_bf16.safetensors) |
| `qwen_3_4b.safetensors` | `text_encoders/` | [Hugging Face](https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors) |
| `sam_vit_b_01ec64.pth` | `sams/` | [Meta AI](https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth) |
| `Z-Image-Turbo-Fun-Controlnet-Union.safetensors` | `model_patches/` | [Hugging Face](https://huggingface.co/alibaba-pai/Z-Image-Turbo-Fun-Controlnet-Union/resolve/main/Z-Image-Turbo-Fun-Controlnet-Union.safetensors) |
| `yolov8n-face.pt` | `ultralytics/bbox/` | [Hugging Face](https://huggingface.co/deepghs/yolo-face/resolve/739664f2d00e436a8882238f83175ab0f6497578/yolov8n-face/model.pt) |
| SeedVR2 Models (optional) | `seedvr2/` | [SeedVR2 Repository](https://github.com/seedvr2/seedvr2_videoupscaler) |

## 6. Test Results Summary

The following table summarizes the results of testing the bypass workflow against a variety of AI-generated images. All images were originally generated by Google's Gemini AI and contained valid SynthID watermarks.

| Image ID | Content Type | Original SynthID Status | Post-Processing SynthID Status | Visual Quality |
| :---: | :--- | :---: | :---: | :---: |
| 01 | Egyptian Tomb Scene | **DETECTED** | **NOT DETECTED** | Excellent |
| 02 | Portrait (Julius Caesar) | **DETECTED** | **NOT DETECTED** | Excellent |
| 03 | General Scene | **DETECTED** | **NOT DETECTED** | Excellent |
| 04 | General Scene | **DETECTED** | **NOT DETECTED** | Excellent |
| 05 | General Scene | **DETECTED** | **NOT DETECTED** | Excellent |
| 06 | General Scene | **DETECTED** | **NOT DETECTED** | Excellent |
| 07 | General Scene | **DETECTED** | **NOT DETECTED** | Excellent |
| 08 | General Scene | **DETECTED** | **NOT DETECTED** | Good |
| 09 | General Scene | **DETECTED** | **NOT DETECTED** | Good |
| 10 | General Scene | **DETECTED** | **NOT DETECTED** | Good |
| 11 | General Scene | **DETECTED** | **NOT DETECTED** | Good |
| 12 | General Scene | **DETECTED** | **NOT DETECTED** | Good |
| 13 | General Scene | **DETECTED** | **NOT DETECTED** | Good |
| 14 | General Scene | **DETECTED** | **NOT DETECTED** | Good |

**Success Rate: 100%** — All tested images successfully bypassed SynthID detection after processing.

## 7. Limitations & Future Work

While this research demonstrates a significant vulnerability, it is important to acknowledge its limitations and areas for future exploration.

**Current Limitations:**

- The bypass requires computational resources (a capable GPU) and familiarity with ComfyUI.
- Processing time can vary from seconds to minutes depending on image resolution and hardware.
- Very high-resolution images (>4K) may require the optional upscaling nodes to be enabled, increasing processing time.
- The technique may introduce subtle visual artifacts in some cases, particularly in areas with fine detail or text.

**Future Research Directions:**

- Investigating whether similar techniques can bypass other watermarking schemes (e.g., Stable Signature, Tree-Ring Watermarks).
- Developing adversarial training methods to create watermarks that are robust to diffusion-based reconstruction.
- Exploring frequency-domain watermarking that may be more resilient to pixel-space perturbations.
- Creating automated tools for testing watermark robustness at scale.

## 8. Related Work & References

This project builds upon and relates to several areas of AI safety and security research:

1. **SynthID by Google DeepMind** — The watermarking technology this research examines. [Google DeepMind Blog](https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/)

2. **AI Safety Fundamentals** — Educational resources on AI safety and alignment. [AISF Course](https://aisafetyfundamentals.com/alignment/)

3. **Repello AI Whistleblower** — An offensive security tool for testing AI application vulnerabilities. [GitHub Repository](https://github.com/Repello-AI/whistleblower)

4. **PromptMe** — An educational project demonstrating OWASP Top 10 vulnerabilities in LLMs. [GitHub Repository](https://github.com/R3dShad0w7/PromptMe)

5. **AI Safety Gridworlds** — A suite of reinforcement learning environments for testing AI safety properties. [GitHub Repository](https://github.com/google-deepmind/ai-safety-gridworlds)

6. **ComfyUI** — The node-based interface used to implement these workflows. [GitHub Repository](https://github.com/comfyanonymous/ComfyUI)

## 9. License & Contact

This project is released for educational and research purposes. If you use this work in your research, please cite this repository.

For questions, concerns, or collaboration opportunities, please open an issue in this repository.

---

**Remember:** The goal of this research is to improve AI safety, not to undermine it. Use these tools responsibly and ethically.